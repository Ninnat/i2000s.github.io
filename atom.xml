<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Schur's Lemming</title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2018-03-07T04:03:29+00:00</updated>
 <id></id>
 <author>
   <name>Ninnat Dangniam</name>
   <email>truecrimson@gmail.com</email>
 </author>

 
 <entry>
   <title>Representation Theory Primer</title>
   <link href="/representation-primer.html"/>
   <updated>2018-03-06T00:00:00+00:00</updated>
   <id>h/representation-primer</id>
   <content type="html">&lt;p&gt;&lt;em&gt;As a general warning, these primers are mainly here just to set up notations and introduce basic definitions and facts that I will refer to in my main posts, so they are a bit lacking in motivation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The following is adapted from Chapter 2 of my thesis, which is an introduction to the representation theory of Lie groups and their associated homogeneous spaces.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Group representations are a special kind of group homomorphisms. A &lt;em&gt;group homomorphism&lt;/em&gt; between two groups is a map &lt;span class=&quot;math&quot;&gt;\(\varphi:G \to G&amp;#39;\)&lt;/span&gt; that respects the group composition law: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\varphi(g_1)\varphi(g_2) &amp;amp;= \varphi(g_1 g_2)\end{aligned}\]&lt;/span&gt; for all &lt;span class=&quot;math&quot;&gt;\(g_1,g_2 \in G\)&lt;/span&gt;. This implies, among other things, that if &lt;span class=&quot;math&quot;&gt;\(e\)&lt;/span&gt; is the identity element of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;, then &lt;span class=&quot;math&quot;&gt;\(\varphi(e)\)&lt;/span&gt; is the identity element of &lt;span class=&quot;math&quot;&gt;\(G&amp;#39;\)&lt;/span&gt;, and &lt;span class=&quot;math&quot;&gt;\(\varphi(g)^{-1} = \varphi(g^{-1})\)&lt;/span&gt;. The &lt;em&gt;kernel&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\(\ker \varphi\)&lt;/span&gt; of a homomorphism &lt;span class=&quot;math&quot;&gt;\(\varphi\)&lt;/span&gt; is the set of elements of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; that are sent to the identity element.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;representation&lt;/em&gt; of a group &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is a homomorphism from &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(\gr{GL}{V}\)&lt;/span&gt;, the group of all invertible matrices on &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\rep: G \to \gr{GL}{V}.\end{aligned}\]&lt;/span&gt; We also say that &lt;span class=&quot;math&quot;&gt;\((\rep,V)\)&lt;/span&gt; is a &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;-representation. When no confusion arises, we also call the vector space &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; itself a representation. A representation &lt;span class=&quot;math&quot;&gt;\(\rep\)&lt;/span&gt; is said to be &lt;em&gt;faithful&lt;/em&gt; if the map &lt;span class=&quot;math&quot;&gt;\(\rho\)&lt;/span&gt; is one-one. A &lt;em&gt;subrepresentation&lt;/em&gt; is a subspace of &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; stable under &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; i.e. closed under every &lt;span class=&quot;math&quot;&gt;\(\rep(g)\)&lt;/span&gt;. An &lt;em&gt;irreducible representation&lt;/em&gt; or &lt;em&gt;irrep&lt;/em&gt; for short is one that has no nontrivial subrepresentation.&lt;/p&gt;
&lt;p&gt;A reducible representation may not decompose as a direct sum of subrepresentations. This is true even for a single matrix. A matrix always has at least one eigenvector in &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}\)&lt;/span&gt; but it may not be diagonalizable. For instance, the group of integers with addition as group multiplication &lt;span class=&quot;math&quot;&gt;\((\mathbb{Z},+)\)&lt;/span&gt; has a two-dimensional representation with the generator &lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\rep(e) &amp;amp;= \begin{pmatrix}
1 &amp;amp; 1 \\
0 &amp;amp; 1
\end{pmatrix},\end{aligned}\]&lt;/span&gt; which cannot be diagonalized. A representation &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; is &lt;em&gt;completely reducible&lt;/em&gt; if for any subrepresentation &lt;span class=&quot;math&quot;&gt;\(W \subset V\)&lt;/span&gt;, there is a complementary subrepresentation &lt;span class=&quot;math&quot;&gt;\(W&amp;#39;\subset V\)&lt;/span&gt; such that &lt;span class=&quot;math&quot;&gt;\(V \simeq W \oplus W&amp;#39;\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As every vector space comes with the dual space, every representation comes with the dual representation. Recall that the dual space &lt;span class=&quot;math&quot;&gt;\(V^*\)&lt;/span&gt; of a complex vector space is the vector space of all linear maps from &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}\)&lt;/span&gt;. Since &lt;span class=&quot;math&quot;&gt;\(V^*\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; have the same dimension, they are isomorphic as vector spaces &lt;span class=&quot;math&quot;&gt;\(V^* \simeq V\)&lt;/span&gt; but not naturally. (We do not assume the Hermitian inner product structure for a moment.) Nevertheless, if we pick an ordered basis &lt;span class=&quot;math&quot;&gt;\(\{ \ket{v_j} \}\)&lt;/span&gt;, an isomorphism amounts to the transposition—simply flipping the ket &lt;span class=&quot;math&quot;&gt;\(\ket{v_j}\)&lt;/span&gt; to the bra &lt;span class=&quot;math&quot;&gt;\(\bra{v_j}\)&lt;/span&gt;. The &lt;em&gt;dual representation&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\((\rep^*,V^*)\)&lt;/span&gt; of a representation &lt;span class=&quot;math&quot;&gt;\((\rep,V)\)&lt;/span&gt; can be defined in &lt;a href=&quot;https://math.berkeley.edu/~reb/courses/261/31.pdf&quot;&gt;several ways&lt;/a&gt;, which can be quite confusing. We follow Fulton and Harris &lt;a href=&quot;#fn2&quot; class=&quot;footnoteRef&quot; id=&quot;fnref2&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; and define the &lt;em&gt;right action&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\(\bra{u} \rep^*(g)\)&lt;/span&gt; so that &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
(\bra{u} \rep^* (g) ) (\rep(g) \ket{v}) &amp;amp;= \braket{u|v},
\end{aligned}\]&lt;/span&gt; for all &lt;span class=&quot;math&quot;&gt;\(\ket{u},\ket{v} \in V\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(g \in G\)&lt;/span&gt;. (The inverse is necessary to make &lt;span class=&quot;math&quot;&gt;\(\rep^*\)&lt;/span&gt; a group homomorphism.) Note that if we want to turn the right action to the &lt;em&gt;left action&lt;/em&gt; on &lt;span class=&quot;math&quot;&gt;\(u\)&lt;/span&gt;, the matrix representation of &lt;span class=&quot;math&quot;&gt;\(\rep^*(g)\)&lt;/span&gt; is given by the transpose &lt;span class=&quot;math&quot;&gt;\(\rep^T(g^{-1})\)&lt;/span&gt; so that &lt;span class=&quot;math&quot;&gt;\(\bra{u} \rep^*(g) = \bra{\rep^T(g^{-1})u}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A representation is &lt;em&gt;unitary&lt;/em&gt; if it is equivalent to a representation in which every &lt;span class=&quot;math&quot;&gt;\(\rep(g)\)&lt;/span&gt; is a unitary operator, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\rep\dgg (g) \rep(g) &amp;amp;= \id,\end{aligned}\]&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(\rep\dgg (g)\)&lt;/span&gt; is the entry-wise complex conjugate transpose of &lt;span class=&quot;math&quot;&gt;\(\rep(g)\)&lt;/span&gt;. For a unitary representation, the right-action version of the dual representation coincides with the &lt;em&gt;Hermitian dual representation&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\(\rho\dgg (g)\)&lt;/span&gt;, while the left-action version coincides with the &lt;em&gt;complex conjugate representation&lt;/em&gt;. High energy physicists like to use the latter, signifying the dual representation by an overbar.&lt;/p&gt;
&lt;h2 id=&quot;intertwiners-and-schurs-lemma&quot;&gt;Intertwiners and Schur’s lemma&lt;/h2&gt;
For complex vector spaces &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(W\)&lt;/span&gt;, define &lt;span class=&quot;math&quot;&gt;\(\text{Hom}(V,W)\)&lt;/span&gt; to be the vector space of linear maps (linear homomorphisms) from &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(W\)&lt;/span&gt;. When &lt;span class=&quot;math&quot;&gt;\(V = W\)&lt;/span&gt;, this space is also denoted by &lt;span class=&quot;math&quot;&gt;\(\text{End}(V)\)&lt;/span&gt; (endomorphisms). Naturally, &lt;span class=&quot;math&quot;&gt;\(\text{Hom}(V,W) \simeq W \otimes V^*\)&lt;/span&gt;. When &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(W\)&lt;/span&gt; are endowed with &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;-representations &lt;span class=&quot;math&quot;&gt;\(\rep_1\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\rep_2\)&lt;/span&gt;, respectively, an &lt;em&gt;intertwiner&lt;/em&gt; between &lt;span class=&quot;math&quot;&gt;\(\rep_1\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\rep_2\)&lt;/span&gt; is defined as a linear map &lt;span class=&quot;math&quot;&gt;\(\varphi\)&lt;/span&gt; that makes the diagram below commutative for any &lt;span class=&quot;math&quot;&gt;\(g\in G\)&lt;/span&gt;.
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/03-2018/intertwiner.png&quot; style=&quot;width: 200px;&quot;/&gt;
&lt;/center&gt;
&lt;!-- $$\begin{aligned}
\xymatrix{V\ar[r]^{\varphi}\ar[d]_{\rep_1(g)} &amp; W\ar[d]^{\rep_2(g)} \\
    V\ar[r]^{\varphi} &amp; W}\end{aligned}$$--&gt;
&lt;p&gt;In other words, &lt;span class=&quot;math&quot;&gt;\(\varphi\)&lt;/span&gt; commutes with the &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;-action: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\varphi \rep_1 (g) &amp;amp;= \rep_2 (g) \varphi.\end{aligned}\]&lt;/span&gt; The set of all such intertwiners forms a subspace of &lt;span class=&quot;math&quot;&gt;\(\text{Hom}(V,W)\)&lt;/span&gt; denoted by &lt;span class=&quot;math&quot;&gt;\(\text{Hom}_G (V,W)\)&lt;/span&gt; or, again, &lt;span class=&quot;math&quot;&gt;\(\text{End}_G (V)\)&lt;/span&gt; when &lt;span class=&quot;math&quot;&gt;\(V \simeq W\)&lt;/span&gt;. Two representations &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(W\)&lt;/span&gt; of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; are said to be &lt;em&gt;equivalent&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
V \stackrel{G}{\simeq} W\end{aligned}\]&lt;/span&gt; when &lt;span class=&quot;math&quot;&gt;\(\text{Hom}_G (V,W)\)&lt;/span&gt; contains an invertible intertwiner. In this case, they are related just by a change of basis.&lt;/p&gt;
&lt;p&gt;Schur proved a collection of elementary but very powerful observations that, in an algebraically closed field &lt;span class=&quot;math&quot;&gt;\(K\)&lt;/span&gt; (such as &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}\)&lt;/span&gt;), intertwiners between irreps behave like the Kronecker delta: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\text{Hom}_G (V,W) \simeq
    \begin{cases}
        K, &amp;amp; V \simeq W, \\
        0, &amp;amp; V \not\simeq W.
    \end{cases}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lemma&lt;/strong&gt; (Schur):&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;Every intertwiner between irreps of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is either an isomorphism or zero,&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For a finite-dimensional irrep &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; in an algebraically closed field &lt;span class=&quot;math&quot;&gt;\(K\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\(\text{End}_G (V)\)&lt;/span&gt; is proportional to the identity operator, &lt;span class=&quot;math&quot;&gt;\(\text{End}_G (V) = k\id\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\(k \in K\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; The first observation is proved by noting that the image and the kernel of an intertwiner are subrepresentations. If either is nontrivial, then the irrep has a nontrivial subrepresentation, which is a contradiction.&lt;/p&gt;
&lt;p&gt;For the second observation, let &lt;span class=&quot;math&quot;&gt;\(\varphi \in \text{End}_G (V)\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; be an eigenvalue (which exists because &lt;span class=&quot;math&quot;&gt;\(K\)&lt;/span&gt; is algebraically closed). Consider &lt;span class=&quot;math&quot;&gt;\(\varphi - \lambda \id\)&lt;/span&gt;. It is also in &lt;span class=&quot;math&quot;&gt;\(\text{Hom}_G (V)\)&lt;/span&gt; because &lt;span class=&quot;math&quot;&gt;\(\id\)&lt;/span&gt; commutes with every operator on &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt;. But &lt;span class=&quot;math&quot;&gt;\(\ker (\varphi - \lambda \id)\)&lt;/span&gt; is a subrepresentation. Therefore &lt;span class=&quot;math&quot;&gt;\(\varphi - \lambda \id\)&lt;/span&gt; must be the zero map i.e. &lt;span class=&quot;math&quot;&gt;\(\varphi = \lambda \id\)&lt;/span&gt;. &lt;span class=&quot;math&quot;&gt;\(\square\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The assumption that &lt;span class=&quot;math&quot;&gt;\(K\)&lt;/span&gt; is algebraically closed is necessary. Consider a representation of &lt;span class=&quot;math&quot;&gt;\(\mathbb{Z}_4\)&lt;/span&gt; on &lt;span class=&quot;math&quot;&gt;\(\mathbb{R}^2\)&lt;/span&gt; as discrete rotations with the generator &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\rep(e) = \begin{pmatrix}
0 &amp;amp; -1 \\
1 &amp;amp; 0
\end{pmatrix}.\end{aligned}\]&lt;/span&gt; It is irreducible because &lt;span class=&quot;math&quot;&gt;\(\rep(e)\)&lt;/span&gt; cannot be diagonalized over &lt;span class=&quot;math&quot;&gt;\(\mathbb{R}\)&lt;/span&gt;. But every &lt;span class=&quot;math&quot;&gt;\(\rep(g)\)&lt;/span&gt; commutes with matrices of the form &lt;span class=&quot;math&quot;&gt;\(a\id + b\rep(e)\)&lt;/span&gt; for some &lt;span class=&quot;math&quot;&gt;\(a,b \in \mathbb{R}\)&lt;/span&gt;, a two-dimensional real vector space.&lt;/p&gt;
&lt;p&gt;An easy corollary is that every complex irrep of an abelian group is one-dimensional because &lt;span class=&quot;math&quot;&gt;\(\rep(g_1)\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\rep(g_2)\)&lt;/span&gt; commute for every &lt;span class=&quot;math&quot;&gt;\(g_1,g_2 \in G\)&lt;/span&gt;. So they are all proportional to the identity operator.&lt;/p&gt;
&lt;p&gt;Another consequence of Schur’s lemma is the “orthogonality of matrix elements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: Let &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; be a finite group and &lt;span class=&quot;math&quot;&gt;\(d_{\lambda}\)&lt;/span&gt; be the dimension of an irrep &lt;span class=&quot;math&quot;&gt;\(\rep_{\lambda}\)&lt;/span&gt; of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;. &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
    \frac{1}{|G|} \sum_g  \rep_{\lambda}(g)_{jk} \left( \rep_{\lambda&amp;#39;}(g)_{mn} \right)^*
    &amp;amp;= \frac{1}{d_{\lambda}} \delta_{\lambda \lambda&amp;#39;} \delta_{jm} \delta_{kn}
    \end{aligned}\]&lt;/span&gt; That is, the matrix elements &lt;span class=&quot;math&quot;&gt;\((d_{\lambda} / |G|)^{1/2} \rep_{\lambda}(g)_{jk}\)&lt;/span&gt; of irreps are orthonormal as functions over &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof&lt;/em&gt;. For any linear map &lt;span class=&quot;math&quot;&gt;\(A:V_{\lambda&amp;#39;} \to V_{\lambda}\)&lt;/span&gt;, its twirl &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
    \frac{1}{|G|} \sum_{g \in G} \rep_{\lambda}(g) A \rep_{\lambda&amp;#39;}(g^{-1})
\end{aligned}\]&lt;/span&gt; is an intertwiner between the two irreps. Therefore, by Schur’s lemma, it is either proportional to the identity or the zero operator. Setting &lt;span class=&quot;math&quot;&gt;\(A = \ketbra{k}{n}\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
    \frac{1}{|G|} \sum_{g \in G} \rep_{\lambda}(g) \ketbra{k}{n} \rep_{\lambda&amp;#39;}(g^{-1})
    &amp;amp;=  N \delta_{\lambda \lambda&amp;#39;} \id_{d_{\lambda}},
\end{aligned}\]&lt;/span&gt; Taking the trace gives &lt;span class=&quot;math&quot;&gt;\(N = \delta_{kn}/d_{\lambda}\)&lt;/span&gt; and taking the &lt;span class=&quot;math&quot;&gt;\(j,m\)&lt;/span&gt; matrix element gives the desired result. &lt;span class=&quot;math&quot;&gt;\(\square\)&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;every-finite-dimensional-representation-of-a-compact-group-is-unitary-and-completely-reducible&quot;&gt;Every finite-dimensional representation of a compact group is unitary and completely reducible&lt;/h2&gt;
&lt;p&gt;Any finite-dimensional representation of a compact group, possessing a Haar measure, is unitary. A measure &lt;span class=&quot;math&quot;&gt;\(dg\)&lt;/span&gt; on &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is a &lt;em&gt;Haar measure&lt;/em&gt; when it is left-invariant i.e. for any integrable function &lt;span class=&quot;math&quot;&gt;\(f\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\int dg_1 f(g_2 g_1) &amp;amp;= \int dg_1 f(g_1),\end{aligned}\]&lt;/span&gt; and normalized, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\int dg &amp;amp;= 1.\end{aligned}\]&lt;/span&gt; For a compact group, it is unique and also right-invariant &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\int dg_1 f(g_1 g_2) &amp;amp;= \int dg_1 f(g_1).\end{aligned}\]&lt;/span&gt; (Of course, when &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is finite this is just a sum.) Armed with the Haar measure, if &lt;span class=&quot;math&quot;&gt;\(\rep(g)\)&lt;/span&gt; is not unitary under some sesquilinear inner product &lt;span class=&quot;math&quot;&gt;\(\braket{v|w}\)&lt;/span&gt;, redefine the inner product to be the average &lt;span class=&quot;math&quot;&gt;\(\int dg \braket{\rep(g)v|\rep(g)w}\)&lt;/span&gt;. This new inner product (which amounts to a change of basis) can be seen to be invariant under the &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;-action: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\int dg_1 \braket{\rep(g_1)v|\rep^*(g_2) \rep(g_2)|\rep(g_1)w}
&amp;amp;= \int dg_1 \braket{\rep(g_2 g_1)v|\rep(g_2 g_1)w} \\
&amp;amp;= \int dg \braket{\rep(g)v|\rep(g)w}.\end{aligned}\]&lt;/span&gt; where we have used the left-invariance of the Haar measure. Thus unitarity is not an additional assumption when we deal with compact groups. The existence of an invariant inner product also provides an easy proof that every finite-dimensional representation is completely reducible. Given a subrepresentation &lt;span class=&quot;math&quot;&gt;\(W\)&lt;/span&gt; of &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt;, the orthogonal complement &lt;span class=&quot;math&quot;&gt;\(W^{\perp}\)&lt;/span&gt; is also stable under &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;. Therefore, &lt;span class=&quot;math&quot;&gt;\(V \simeq W \oplus W^{\perp}\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id=&quot;isotypic-decomposition&quot;&gt;Isotypic decomposition&lt;/h2&gt;
&lt;p&gt;Let &lt;span class=&quot;math&quot;&gt;\(\hat{G}\)&lt;/span&gt; be the collection of all inequivalent irreps of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;. A completely reducible representation (by definition) decomposes into the orthogonal direct sum of irreps &lt;span class=&quot;math&quot;&gt;\(V_{\lambda}\)&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
V &amp;amp;\stackrel{G}{\simeq} \bigoplus_{\lambda \in \hat{G}} \bigoplus^{n_{\lambda}} V_{\lambda},\end{aligned}\]&lt;/span&gt; each with (possibly zero) &lt;em&gt;multiplicity&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\(n_{\lambda}\)&lt;/span&gt;. A decomposition is said to be &lt;em&gt;multiplicity-free&lt;/em&gt; if every &lt;span class=&quot;math&quot;&gt;\(n_{\lambda}\)&lt;/span&gt; is either 0 or 1. By Schur’s lemma, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\text{Hom}_G (V_{\lambda},V) &amp;amp;= \bigoplus^{n_{\lambda}} \text{Hom}_G ( V_{\lambda}, V_{\lambda} ) = \mathbb{C}^{n_{\lambda}}.\end{aligned}\]&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}^{n_{\lambda}}\)&lt;/span&gt; is called the &lt;em&gt;multiplicity space&lt;/em&gt; where &lt;span class=&quot;math&quot;&gt;\(n_{\lambda} = \dim \text{Hom}_G (V_{\lambda},V)\)&lt;/span&gt;. Putting these together, we obtain the &lt;em&gt;isotypic decomposition&lt;/em&gt; of &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt;: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
V &amp;amp;\stackrel{G}{\simeq} \bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes \mathbb{C}^{n_{\lambda}}
\stackrel{G}{\simeq} \bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes \text{Hom}_G (V_{\lambda},V).\end{aligned}\]&lt;/span&gt; An important special case is when &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; is a tensor product of irreps. &lt;span class=&quot;math&quot;&gt;\(V\)&lt;/span&gt; may not be irreducible and we have the &lt;em&gt;Clebsch-Gordan decomposition&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
    V_{\mu} \otimes V_{\nu} &amp;amp;\stackrel{G}{\simeq} \bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes \mathbb{C}^{n^{\lambda}_{\mu\nu}}.
\end{aligned}\]&lt;/span&gt; The collection of &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; that appears in the direct sum is called the &lt;em&gt;Clebsch-Gordan series&lt;/em&gt;, and the overlap between vectors in &lt;span class=&quot;math&quot;&gt;\(V_{\mu} \otimes V_{\nu}\)&lt;/span&gt; and vectors in &lt;span class=&quot;math&quot;&gt;\(V_{\lambda}\)&lt;/span&gt; are &lt;em&gt;Clebsch-Gordan coefficients&lt;/em&gt;. When &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is a unitary group, the &lt;span class=&quot;math&quot;&gt;\(n^{\lambda}_{\mu\nu}\)&lt;/span&gt; are called &lt;em&gt;Richardson-Littlewood coefficients&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&quot;fourier-analysis&quot;&gt;Fourier analysis&lt;/h2&gt;
&lt;p&gt;For a finite group &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;, define an orthonormal basis &lt;span class=&quot;math&quot;&gt;\(\{\ket{g}|g\in G\}\)&lt;/span&gt;. Its complex span, the &lt;em&gt;group algebra&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt;, is an algebra (a vector space in which two vectors can be multiplied) with multiplication &lt;span class=&quot;math&quot;&gt;\(*\)&lt;/span&gt; inherited from group multiplication &lt;span class=&quot;math&quot;&gt;\(\ket{g_1}*\ket{g_2} = \ket{g_1g_2}\)&lt;/span&gt;: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\left( \sum_{g_1} f_{g_1} \ket{g_1} \right) * \left( \sum_{g_2} h_{g_2} \ket{g_2} \right)
&amp;amp;= \sum_{g_1,g_2} f_{g_1} h_{g_1^{-1} g} \ket{g}.\end{aligned}\]&lt;/span&gt; Here the expression on the right is a discrete analogue of the convolution &lt;span class=&quot;math&quot;&gt;\((f*h)(x) = \int dy f(x)h(y-x)\)&lt;/span&gt;. &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt; can also be naturally thought of as a representation of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; by left multiplication &lt;span class=&quot;math&quot;&gt;\(\rep_L(g_1) \ket{g_2} = \ket{g_1 g_2}\)&lt;/span&gt;, called the &lt;em&gt;left regular representation&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\((\rep_L,\mathbb{C}[G])\)&lt;/span&gt;, or right multiplication &lt;span class=&quot;math&quot;&gt;\(\rep_R(g_1)\ket{g_2} = \ket{g_2 g_1^{-1}}\)&lt;/span&gt;, called the &lt;em&gt;right regular representation&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\((\rep_R,\mathbb{C}[G])\)&lt;/span&gt;. When &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is infinite, we can interpret &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt; to be the convolution algebra of functions on &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;, provided that we agree on what we mean by a function. The standard choice is for &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt; to be &lt;span class=&quot;math&quot;&gt;\(L^2(G)\)&lt;/span&gt;, the space of square-integrable functions. The group action on a function is dual to the action on group algebra, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\rep(g)f(x) &amp;amp;= f(g^{-1} x),\end{aligned}\]&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;\(x \in G\)&lt;/span&gt;, since a function is a linear map from &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A central result in representation theory is the isotypic decomposition of &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt;: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\mathbb{C}[G] &amp;amp;\stackrel{G}{\simeq} \bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes \text{Hom}_G (V_{\lambda},\mathbb{C}[G])
\stackrel{G}{\simeq} \bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes \mathbb{C}^{\dim V_{\lambda}}.
\end{aligned}\]&lt;/span&gt; In words, every irrep appear as many times as its dimension in the regular representation. Since the left and right representations commute, &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt; can also be thought of as a representation of &lt;span class=&quot;math&quot;&gt;\(G \times G\)&lt;/span&gt;. Under this &lt;span class=&quot;math&quot;&gt;\(G \times G\)&lt;/span&gt;-action, &lt;span class=&quot;math&quot;&gt;\(\mathbb{C}[G]\)&lt;/span&gt; decomposes in the multiplicity-free manner: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\label{eq:regular decomposition}
\mathbb{C}[G] \stackrel{G \times G}{\simeq} \bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes V_{\lambda}^*
\stackrel{G \times G}{\simeq} \bigoplus_{\lambda \in \hat{G}} \text{End}(V_{\lambda}),
\end{aligned}\]&lt;/span&gt; where the representation &lt;span class=&quot;math&quot;&gt;\((\rep_L \otimes \id, G\times G)\)&lt;/span&gt; acts on &lt;span class=&quot;math&quot;&gt;\(V_{\lambda}\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\((\id \otimes \rep_R, G\times G)\)&lt;/span&gt; acts on &lt;span class=&quot;math&quot;&gt;\(V_{\lambda}^* \)&lt;/span&gt;. The result is sometimes a part of so-called &lt;strong&gt;Maschke’s theorem&lt;/strong&gt; and can be proved entirely in the language of semisimple algebras &lt;a href=&quot;#fn3&quot; class=&quot;footnoteRef&quot; id=&quot;fnref3&quot;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. Another route (which I took in my thesis) is to use &lt;a href=&quot;http://math.uchicago.edu/~may/REU2015/REUPapers/Chaves.pdf&quot;&gt;&lt;em&gt;Frobenius reciprocity&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The unitary change of basis from &lt;span class=&quot;math&quot;&gt;\(\{\ket{g}\}\)&lt;/span&gt; to an orthonormal basis on the right hand side of  is the &lt;em&gt;Fourier transform&lt;/em&gt;. Its explicit matrix form, given an orthonormal basis &lt;span class=&quot;math&quot;&gt;\(\{\ket{\lambda,j,k}|1\le j,k\le d_{\lambda}\}\)&lt;/span&gt; for each &lt;span class=&quot;math&quot;&gt;\(V_{\lambda} \otimes V_{\lambda}^* \)&lt;/span&gt;, is &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\label{Fourier transform:unitary}
U_{\text{FT}} &amp;amp;= \sum_{g \in G} \sum_{\lambda \in \hat{G}} \sum_{j,k=1}^{d_{\lambda}} \sqrt{\frac{d_{\lambda}}{|G|}} \rep_{\lambda}(g)_{jk} \ketbra{\lambda,j,k}{g} = \sum_{g\in G} \ketbra{\tilde{g}}{g},
\end{aligned}\]&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;\(\ket{\tilde{g}}\)&lt;/span&gt; being the Fourier transform of the discrete delta function &lt;span class=&quot;math&quot;&gt;\(\ket{g}\)&lt;/span&gt;: &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\label{Fourier transform}
\ket{\tilde{g}} &amp;amp;= \sum_{\lambda \in \hat{G}} \sum_{j,k=1}^{d_{\lambda}} \sqrt{\frac{d_{\lambda}}{|G|}} \rep_{\lambda}(g)_{jk} \ket{\lambda,j,k}.
\end{aligned}\]&lt;/span&gt; (Note the choice of the constant &lt;span class=&quot;math&quot;&gt;\(1/\sqrt{|G|}\)&lt;/span&gt;, akin to using &lt;span class=&quot;math&quot;&gt;\(1/(2\pi)\)&lt;/span&gt; in the continuous Fourier transform, is necessary for &lt;span class=&quot;math&quot;&gt;\(U_{\text{FT}}\)&lt;/span&gt; to be unitary).&lt;/p&gt;
&lt;p&gt;For the cyclic group &lt;span class=&quot;math&quot;&gt;\(\mathbb{Z}_n\)&lt;/span&gt;, this is just the discrete Fourier transform &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\label{Fourier transform:Z_n}
U_{\text{FT}} = \frac{1}{\sqrt{n}} \sum_{x,y=0}^{n-1} e^{2\pi ixy/n} \ketbra{y}{x}.  
\end{aligned}\]&lt;/span&gt; More generally, for any abelian group, &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\label{Fourier transform:abelian}
\ket{\tilde{g}} &amp;amp;= \frac{1}{\sqrt{|G|}} \sum_{\lambda \in \hat{G}} \chi_{\lambda}(g) \ket{\lambda},
\end{aligned}\]&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(\chi_{\lambda}(g)\)&lt;/span&gt; is a one-dimensional irrep of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;, also called an &lt;em&gt;(irreducible) &lt;a href=&quot;https://en.wikipedia.org/wiki/Character_theory&quot;&gt;character&lt;/a&gt;&lt;/em&gt;. The Fourier transform on an abelian group is much more well-behaved than the general case because the collection of all distinct irreps &lt;span class=&quot;math&quot;&gt;\(\hat{G}\)&lt;/span&gt; also comes equipped with the abelian group structure. &lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
\chi^{-1}(g) &amp;amp;= \chi(g^{-1}) = \chi^* (g) \\
\chi(g_1)\chi(g_2) &amp;amp;= \chi(g_1 g_2).
\end{aligned}\]&lt;/span&gt; In this case, &lt;span class=&quot;math&quot;&gt;\(\hat{G}\)&lt;/span&gt; is called the &lt;em&gt;dual group&lt;/em&gt;. The &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Pontryagin_duality&quot;&gt;compact-discrete duality&lt;/a&gt;&lt;/em&gt; states that &lt;span class=&quot;math&quot;&gt;\(\hat{G}\)&lt;/span&gt; is compact if &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is discrete and vice versa. Familiar dual pairs are &lt;span class=&quot;math&quot;&gt;\(G = \hat{G} = \mathbb{Z}_d\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\(G = \hat{G} = \mathbb{R}\)&lt;/span&gt;, and &lt;span class=&quot;math&quot;&gt;\(G = \gr{U}{1}\)&lt;/span&gt; dual to &lt;span class=&quot;math&quot;&gt;\(\hat{G} = \mathbb{Z}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For compact groups, we have the celebrated&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; (Peter-Weyl): For a compact Lie group &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(V_{\lambda}\)&lt;/span&gt; its irrep, the orthogonal direct sum &lt;span class=&quot;math&quot;&gt;\(\bigoplus_{\lambda \in \hat{G}} V_{\lambda} \otimes V_{\lambda}^*\)&lt;/span&gt; is dense in &lt;span class=&quot;math&quot;&gt;\(L^2(G)\)&lt;/span&gt; with respect to the supremum norm &lt;span class=&quot;math&quot;&gt;\(||f||_{\infty} = \sup |f(g)|\)&lt;/span&gt;. Moreover, every &lt;span class=&quot;math&quot;&gt;\(V_{\lambda}\)&lt;/span&gt; is finite-dimensional.&lt;/p&gt;
&lt;p&gt;In other words, every function in &lt;span class=&quot;math&quot;&gt;\(L^2(G)\)&lt;/span&gt; can be approximated arbitrarily closely in the supremum norm by a finite linear combinations of the matrix elements &lt;span class=&quot;math&quot;&gt;\(\{ \sqrt{d_{\lambda}} \rep_{\lambda}(g)_{jk} \}\)&lt;/span&gt;. Thus, the matrix elements are not only orthonormal but also complete. This is a generalization of Fourier analysis and orthogonal polynomials and special functions to arbitrary groups.&lt;/p&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;Not to be confused with physicists’ (infinitesimal) “generators&amp;quot; of a Lie group which are Lie algebra elements&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn2&quot;&gt;&lt;p&gt;Page 4 of William Fulton and Joe Harris, &lt;em&gt;Representation Theory: A First Course&lt;/em&gt;, Springer, 1999&lt;a href=&quot;#fnref2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn3&quot;&gt;&lt;p&gt;Pavel Etingof &lt;em&gt;et al.&lt;/em&gt;, &lt;em&gt;Introduction to Representation Theory&lt;/em&gt;, AMS, 2011&lt;a href=&quot;#fnref3&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>Adjoint functors</title>
   <link href="/adjoint-functors.html"/>
   <updated>2017-09-20T00:00:00+00:00</updated>
   <id>h/adjoint-functors</id>
   <content type="html">&lt;p&gt;First published: &lt;em&gt;26 Jan 2017&lt;/em&gt;; Status: &lt;em&gt;In progress&lt;/em&gt;&lt;/p&gt;
&lt;!-- Lately I&#39;ve been thinking about induced representations and the Frobenius reciprocity which have a natural interpretation in terms of adjoint functor in category theory. This post is an introduction to the categorical point of view that I need at the level I&#39;m comfortable with. (You can find better general introductions out there by mathematicians such as [this 3-parter](https://topologicalmusings.wordpress.com/category/math-topics/category-theory/category-theory-for-beginners/) by Todd Trimble.)
--&gt;

&lt;p&gt;&lt;strong&gt;I.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;one of the most powerful lessons from category theory is that knowing the relations between an object with other objects is as good as knowing the object itself, as the object can be defined by these relations. A lot of time there is a unique (up to a natural isomorphism which doesn’t entail making any arbitrary choice) object that has a “universal” property that can simulate the relations to all other objects of the same kind and so can be thought of as the “best” object of its kind. All of these can be represented graphically by objects and arrows. I will give some examples of these on the way but let us first define what categories are.&lt;/p&gt;
&lt;h2 id=&quot;categories&quot;&gt;Categories&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;category&lt;/strong&gt; &lt;span class=&quot;math&quot;&gt;\(\mathcal{C}\)&lt;/span&gt; is a class of objects and morphisms between them. If &lt;span class=&quot;math&quot;&gt;\(X\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(Y\)&lt;/span&gt; are &lt;strong&gt;objects&lt;/strong&gt; in &lt;span class=&quot;math&quot;&gt;\(\mathcal{C}\)&lt;/span&gt;, the class of &lt;strong&gt;morphisms&lt;/strong&gt; between &lt;span class=&quot;math&quot;&gt;\(X\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(Y\)&lt;/span&gt; is denoted by &lt;span class=&quot;math&quot;&gt;\(\text{Hom}(X,Y)\)&lt;/span&gt;. They are also represented diagrammatically as arrows &lt;span class=&quot;math&quot;&gt;\(f:X \to Y\)&lt;/span&gt; for &lt;span class=&quot;math&quot;&gt;\(f \in \text{Hom}(X,Y)\)&lt;/span&gt;. For &lt;span class=&quot;math&quot;&gt;\(\mathcal{C}\)&lt;/span&gt; to be a category, there must be a identity morphism and the compositions of morphisms must be associative. Here are some categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Set&lt;/strong&gt; of all sets. Since there is no &lt;a href=&quot;https://en.wikipedia.org/wiki/Russell%27s_paradox&quot;&gt;set of all sets&lt;/a&gt;, the word “class” in the definition of a category cannot be replaced by “set”. The morphisms are arbitrary maps between sets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grp&lt;/strong&gt; of all groups, &lt;strong&gt;Ring&lt;/strong&gt; of all rings, and &lt;strong&gt;Field&lt;/strong&gt;&lt;span class=&quot;math&quot;&gt;\(_p\)&lt;/span&gt; of all fields with &lt;a href=&quot;https://en.wikipedia.org/wiki/Category_of_rings#Category_of_fields&quot;&gt;characteristic&lt;/a&gt; &lt;span class=&quot;math&quot;&gt;\(p=0\)&lt;/span&gt; or a prime number with the respective homomorphisms as morphisms. (There is no homomorphism between fields of different characteristics.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Top&lt;/strong&gt; of topological spaces with continuous maps as morphisms. In particular, homeomorphisms are isomorphisms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Man&lt;/strong&gt;&lt;span class=&quot;math&quot;&gt;\(^{\infty}\)&lt;/span&gt; of smooth manifolds with infinitely differentiable maps as morphisms. In particular, diffeomorphisms are isomorphisms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vec&lt;/strong&gt;&lt;span class=&quot;math&quot;&gt;\(_k\)&lt;/span&gt; of vector spaces over a field &lt;span class=&quot;math&quot;&gt;\(k\)&lt;/span&gt; with linear maps as morphisms.&lt;/li&gt;
&lt;/ul&gt;
My favorite elementary example of uniquely defining an object by morphisms is the construction of a product and a coproduct. A &lt;strong&gt;product&lt;/strong&gt; of &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt; is an object &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; together with a morphism from &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt; such that, if &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; is another object also equipped with some morphisms to &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt;, then there is a unique morphism from &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; such that the following diagram “commutes” (so we call this kind of diagrams commutative diagrams), meaning that every way to compose such morphisms to go from &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; or &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt; gives the same result.
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/product.png&quot; style=&quot;width: 200px;&quot;/&gt;
&lt;/center&gt;
&lt;!-- \begin{align*}
    \xymatrix{
      &amp; D \ar[dl]_{\alpha&#39;}\ar[d]^{\gamma}\ar[dr]^{\beta&#39;} &amp; \\
      A &amp; C\ar[l]^{\alpha}\ar[r]_{\beta} &amp; B
    }
\end{align*} --&gt;
&lt;p&gt;The rational behind this definition is that &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; together with the mappings &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\beta\)&lt;/span&gt; is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Universal_property&quot;&gt;best&lt;/a&gt; object that acts as a product of &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt; since giving any morphism from any object &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; or &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt; is equivalent to giving &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\beta\)&lt;/span&gt; from &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt;, so we can just forget about &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; altogether and regard &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; as a universal simulator of such relations.&lt;/p&gt;
The same diagram with all arrows reversed defines a &lt;strong&gt;coproduct&lt;/strong&gt; &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt;.
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/coproduct.png&quot; style=&quot;width: 200px;&quot;/&gt;
&lt;/center&gt;
&lt;!-- \begin{align*}
    \xymatrix{
      &amp; D &amp; \\
      A\ar[ur]^{\alpha&#39;}\ar[r]_{\alpha} &amp; C\ar[u]_{\gamma} &amp; B\ar[l]^{\beta}\ar[ul]_{\beta&#39;}
    }
\end{align*} --&gt;
&lt;p&gt;In &lt;strong&gt;Set&lt;/strong&gt;, the product is the direct product &lt;span class=&quot;math&quot;&gt;\(A \times B\)&lt;/span&gt; and the coproduct is the disjoint union &lt;span class=&quot;math&quot;&gt;\(A \amalg B\)&lt;/span&gt;. We will just verify the first statement to familiarize ourselves with the meaning of the diagrams. For the direct product &lt;span class=&quot;math&quot;&gt;\(C=A \times B\)&lt;/span&gt;, a natural choice for the mappings &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\beta\)&lt;/span&gt; is the projection &lt;span class=&quot;math&quot;&gt;\[ \begin{aligned}
\alpha(a,b) = a, &amp;amp;&amp;amp; \beta(a,b) = b.
\end{aligned} \]&lt;/span&gt; We have to show that, for any &lt;span class=&quot;math&quot;&gt;\(\alpha&amp;#39;\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\beta&amp;#39;\)&lt;/span&gt; from a set &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt;, there is a morphism &lt;span class=&quot;math&quot;&gt;\(\gamma\)&lt;/span&gt; from &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; that makes the diagram commutes and uniquely so. Obviously, for &lt;span class=&quot;math&quot;&gt;\(d\in D\)&lt;/span&gt;, this map is &lt;span class=&quot;math&quot;&gt;\[ \begin{aligned}
\gamma(d) = (\alpha&amp;#39;(d),\beta&amp;#39;(d)),
\end{aligned} \]&lt;/span&gt; If there is another map &lt;span class=&quot;math&quot;&gt;\(\gamma&amp;#39;\)&lt;/span&gt; from &lt;span class=&quot;math&quot;&gt;\(D\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; that makes the diagram commutes, it must sends &lt;span class=&quot;math&quot;&gt;\(d\)&lt;/span&gt; to an element of &lt;span class=&quot;math&quot;&gt;\(A \times B\)&lt;/span&gt; that projects to &lt;span class=&quot;math&quot;&gt;\(\alpha&amp;#39;(d)\)&lt;/span&gt; on &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\beta&amp;#39;(d)\)&lt;/span&gt; on &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt;. But that element is none other than &lt;span class=&quot;math&quot;&gt;\((\alpha&amp;#39;(d),\beta&amp;#39;(d))\)&lt;/span&gt;. Thus, the uniqueness is established. For the disjoint union &lt;span class=&quot;math&quot;&gt;\(C = A \amalg B\)&lt;/span&gt;, a natural choice for the mappings &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\beta\)&lt;/span&gt; is the embedding of &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt; into the union. Then the proof proceeds in the same manner by making obvious choices and following the arrows around (“diagram chasing”).&lt;/p&gt;
We can ask if the direct product and the direct sum of sets are the only product and coproduct objects in &lt;strong&gt;Set&lt;/strong&gt;. The nice answer is that they are. And this is not only true in &lt;strong&gt;Set&lt;/strong&gt; but also in a general category as well. Let us show this for the categorical product in &lt;strong&gt;Set&lt;/strong&gt;. Suppose that we have two product objects &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(C&amp;#39;\)&lt;/span&gt;. Then there are unique morphisms in both directions, &lt;span class=&quot;math&quot;&gt;\(\gamma: C&amp;#39; \to C\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\gamma&amp;#39;:C \to C&amp;#39;\)&lt;/span&gt;, that make the diagram commutes.
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/product-uniqueness.png&quot; style=&quot;width: 200px;&quot;/&gt;
&lt;/center&gt;
&lt;!--
\begin{align*}
    \xymatrix{
      &amp; C&#39; \ar[dl]_{\alpha&#39;}\ar[d]^{\gamma}\ar[dr]^{\beta&#39;} &amp; \\
      A &amp; C\ar[l]^{\alpha}\ar[u]^{\gamma&#39;}\ar[r]_{\beta} &amp; B
    }
\end{align*}
--&gt;
&lt;p&gt;Surely &lt;span class=&quot;math&quot;&gt;\(\alpha \circ \gamma \circ \gamma&amp;#39; = \alpha&amp;#39; \circ \gamma&amp;#39; = \alpha\)&lt;/span&gt;. and &lt;span class=&quot;math&quot;&gt;\(\beta \circ \gamma \circ \gamma&amp;#39; = \beta&amp;#39; \circ \gamma&amp;#39; = \beta\)&lt;/span&gt;. But these mean that if we replace &lt;span class=&quot;math&quot;&gt;\(C&amp;#39;\)&lt;/span&gt; in the diagram by &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt;, then &lt;span class=&quot;math&quot;&gt;\(\gamma \circ \gamma&amp;#39;\)&lt;/span&gt; is a unique morphism from &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt; to itself that makes the new diagram commutes. But we know that the identity morphism also makes the diagram commutes, so &lt;span class=&quot;math&quot;&gt;\(\gamma \circ \gamma&amp;#39;\)&lt;/span&gt; has to be the identity morphism.&lt;/p&gt;
&lt;p&gt;Maybe you don’t enjoy this abstract notion of product as I do. Why going so far to define something that should reduce to the notion of a product in any category? Well, it is not always clear what the notion of a product should be. &lt;a href=&quot;https://topologicalmusings.wordpress.com/2008/06/22/basic-category-theory-i/&quot;&gt;Todd Trimble&lt;/a&gt; gives an example in the case of the category &lt;strong&gt;Top&lt;/strong&gt; of all topological spaces.&lt;/p&gt;
&lt;h2 id=&quot;functors&quot;&gt;Functors&lt;/h2&gt;
&lt;p&gt;Suppose that &lt;span class=&quot;math&quot;&gt;\(\mathcal{C}\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\mathcal{D}\)&lt;/span&gt; are two categories and &lt;span class=&quot;math&quot;&gt;\(X,Y \in \mathcal{C}\)&lt;/span&gt;. A (covariant) &lt;strong&gt;functor&lt;/strong&gt; &lt;span class=&quot;math&quot;&gt;\(F\)&lt;/span&gt; is a map (of both objects and morphisms) &lt;span class=&quot;math&quot;&gt;\(F: \mathcal{C} \to \mathcal{D}\)&lt;/span&gt; such that &lt;span class=&quot;math&quot;&gt;\(\text{Hom}(X,Y) \to \text{Hom}(F(X) , F(Y))\)&lt;/span&gt; preserves identity morphisms and compositions.&lt;/p&gt;
&lt;p&gt;One of the more trivial kinds of functors are ones that simply throw away information. The &lt;strong&gt;forgetful functor&lt;/strong&gt; &lt;strong&gt;Grp&lt;/strong&gt; &lt;span class=&quot;math&quot;&gt;\(\to\)&lt;/span&gt; &lt;strong&gt;Set&lt;/strong&gt; sends a group to its underlying set; it completely forgets the group structure. There are also functors that are partially forgetful such as the functor from &lt;strong&gt;Grp&lt;/strong&gt; to &lt;strong&gt;Ab&lt;/strong&gt; the category of all abelian groups which set &lt;span class=&quot;math&quot;&gt;\(gh=hg\)&lt;/span&gt; for all elements &lt;span class=&quot;math&quot;&gt;\(g,h\)&lt;/span&gt; in a group.&lt;/p&gt;
More interesting is the &lt;strong&gt;free functor&lt;/strong&gt; &lt;span class=&quot;math&quot;&gt;\(F:\)&lt;/span&gt; &lt;strong&gt;Set&lt;/strong&gt; &lt;span class=&quot;math&quot;&gt;\(\to\)&lt;/span&gt; &lt;strong&gt;Grp&lt;/strong&gt; sending a set to its “&lt;a href=&quot;https://en.wikipedia.org/wiki/Free_group&quot;&gt;free group&lt;/a&gt;”. For a set &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt;, &lt;span class=&quot;math&quot;&gt;\(F(S)\)&lt;/span&gt; is the set of all expressions that can be composed from elements of &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt;: every power and inverse of each and every element and (noncommutative) products of them; it is the least constrained group that can be built from elements of &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt; as generators. The categorical way to say this is that the free functor has the universal property that giving a map &lt;span class=&quot;math&quot;&gt;\(\sigma\)&lt;/span&gt; from &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt; to some group &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is equivalent to giving a unique group homomorphism &lt;span class=&quot;math&quot;&gt;\(\varphi\)&lt;/span&gt; from the free group &lt;span class=&quot;math&quot;&gt;\(F(S)\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;. (The empty set gives the trivial group.)
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/free-group.png&quot; style=&quot;width: 150px;&quot;/&gt;
&lt;/center&gt;
&lt;!-- \begin{align}
    \xymatrix{
      S \ar[r]\ar[dr]_{\sigma} &amp; F(S) \ar[d]^{\varphi} \\
      &amp; G
    }
\end{align} --&gt;

&lt;p&gt;The free functor sends an object in &lt;strong&gt;Set&lt;/strong&gt; to an object in &lt;strong&gt;Grp&lt;/strong&gt;, and the forgetful functor sends an object in &lt;strong&gt;Grp&lt;/strong&gt; to an object in &lt;strong&gt;Set&lt;/strong&gt;. But their composition is not the identity map. Nevertheless, they are a kind of generalized inverses in the sense formalized in the notion of an adjoint functor.&lt;/p&gt;
Functors &lt;span class=&quot;math&quot;&gt;\(F: \mathcal{C} \to \mathcal{D}\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(G: \mathcal{D} \to \mathcal{C}\)&lt;/span&gt; are &lt;strong&gt;adjoint functors&lt;/strong&gt; if for any &lt;span class=&quot;math&quot;&gt;\(X \in \mathcal{C}\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(Y \in \mathcal{D}\)&lt;/span&gt;, there is an &lt;a href=&quot;https://en.wikipedia.org/wiki/Adjoint_functors#Hom-set_adjunction&quot;&gt;isomorphism&lt;/a&gt; &lt;span class=&quot;math&quot;&gt;\[ \begin{aligned}
\text{Hom}_{\mathcal{D}} (F(X),Y) \simeq \text{Hom}_{\mathcal{C}} (X,G(Y)).
\end{aligned} \]&lt;/span&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/adjoint.png&quot; style=&quot;width: 180px;&quot;/&gt;
&lt;/center&gt;
&lt;!-- \begin{align*}
    \xymatrix{
      F(X)\ar[r]^{\text{Hom}_{\mathcal{D}}(F(X),Y)} &amp; Y\ar[d] \\
      X\ar[u]\ar[r]_{\text{Hom}_{\mathcal{C}}(X,G(Y))} &amp; G(Y)
    }
\end{align*} --&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\(F\)&lt;/span&gt; is called a &lt;strong&gt;left adjoint&lt;/strong&gt; of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; is called a &lt;strong&gt;right adjoint&lt;/strong&gt; of &lt;span class=&quot;math&quot;&gt;\(F\)&lt;/span&gt;.&lt;/p&gt;
Why should this be true in the case of the forgetful functor &lt;span class=&quot;math&quot;&gt;\(R\)&lt;/span&gt; and the free functor &lt;span class=&quot;math&quot;&gt;\(F\)&lt;/span&gt; between &lt;strong&gt;Set&lt;/strong&gt; and &lt;strong&gt;Grp&lt;/strong&gt;? A group homomorphism &lt;span class=&quot;math&quot;&gt;\(\varphi :F(S) \to G\)&lt;/span&gt; is completely determined if we know what it does to each generator of &lt;span class=&quot;math&quot;&gt;\(F(S)\)&lt;/span&gt; i.e. each element of &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt;. In other words, what &lt;span class=&quot;math&quot;&gt;\(\varphi\)&lt;/span&gt; really acts on is the underlying set of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;. That is, giving &lt;span class=&quot;math&quot;&gt;\(\varphi\)&lt;/span&gt; is equivalent to giving &lt;span class=&quot;math&quot;&gt;\(\psi : S \to R(G)\)&lt;/span&gt;. &lt;span class=&quot;math&quot;&gt;\[ \begin{aligned}
\text{Hom}_{\bf{Grp}} (F(S),G) \simeq \text{Hom}_{\bf{Set}} (S,R(G))
\end{aligned} \]&lt;/span&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/free-functor.png&quot; style=&quot;width: 180px;&quot;/&gt;
&lt;/center&gt;
&lt;p&gt;so that the free functor is a left adjoint of the forgetful functor.&lt;/p&gt;
Possessing an adjoint on one side does not imply possessing an adjoint on the other side, as this example also demonstrates; the forgetful functor &lt;span class=&quot;math&quot;&gt;\(R:{\bf Grp} \to {\bf Set}\)&lt;/span&gt; does not have a right adjoint. The desired isomorphism &lt;span class=&quot;math&quot;&gt;\[ \begin{aligned}
\text{Hom}_{\bf{Grp}} (G,F(S)) \simeq \text{Hom}_{\bf{Set}} (R(G),S)
\end{aligned}, \]&lt;/span&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/01-2017/cofree-functor.png&quot; style=&quot;width: 180px;&quot;/&gt;
&lt;/center&gt;
&lt;p&gt;where now &lt;span class=&quot;math&quot;&gt;\(F\)&lt;/span&gt; is a cofree functor, fails when &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt; is an empty set. Given a group homormophism from &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; to &lt;span class=&quot;math&quot;&gt;\(F(S)\)&lt;/span&gt;, there is no corresponding map (with a non-empty image) from &lt;span class=&quot;math&quot;&gt;\(R(G)\)&lt;/span&gt; to an empty set. &lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- A deep understanding of adjoint functors seem to require knowing about representability of functors and Yoneda&#39;s lemma, neither of which I can competently explain. But they all have analogues in linear algebra by pretending that an inner product $\braket{v,u}$ is a morphism $\text{Hom}(v,u)$ in a category with one object $V$ (with linear maps between vector spaces as functors). [^1]. A functor $F:\mathcal{C} \to $**Set** is **representable** by $X \in \mathcal{C}$ if the functor can be concretely realized as the morphism Hom$_{\mathcal{C}}(X,\cdot)$. The **Yoneda&#39;s lemma** guarantees that this $X$ is unique. In this analogy, the representability of $F$ combined with the Yoneda&#39;s lemma has the same content as the [Riesz representation theorem](https://en.wikipedia.org/wiki/Riesz_representation_theorem) in linear algebra. It says that a continuous linear functional $f:V \to k$, where $k$ is now the analog of **Set**, can be identified as a unique vector in $v \in V$ itself via the inner product
$$ \begin{aligned}
f (u) = \braket{v,u}.
\end{aligned} $$
Now consider the linear functional $v \mapsto \braket{L(v),u}$. By the representation theorem, there is $w \in V$ that realizes this map as $\braket{v,w}$. This is an image of the adjoint operator $w = L^*(u)$. By a similar argument, if $F$ and $G$ are adjoint functors
$$ \begin{aligned}
\text{Hom}_{\mathcal{D}} (F(X),Y) \simeq \text{Hom}_{\mathcal{C}} (X,G(Y)),
\end{aligned} $$
and the classes of morphisms are sets (which they usually are), the functor $Y \mapsto \text{Hom}_{\mathcal{C}} (X,G(Y))$ is represented by $F(X)$ and the functor $X \mapsto \text{Hom}_{\mathcal{D}} (F(X),Y)$ is represented by $F(Y)$, so they are unique by the Yoneda&#39;s lemma. A further analogy is that an adjoint functor may not exist, but if it exists, it is unique. --&gt;

&lt;p&gt;&lt;strong&gt;II.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In representation theory, a restriction of a representation of a group &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; to a subgroup &lt;span class=&quot;math&quot;&gt;\(H\)&lt;/span&gt; is a functor whose left adjoint is the induction of a representation of &lt;span class=&quot;math&quot;&gt;\(H\)&lt;/span&gt; to a “free” representation of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;. There, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Induced_representation&quot;&gt;Frobenius reciprocity theorem&lt;/a&gt; is nothing but the property of adjoint functors. I will talk about how this can be used to deduce the well known fact that each irreducible representation of SO(3) appears only once in the decomposition of functions on a sphere.&lt;/p&gt;
&lt;!-- [^1]: Page 102 of Etingof *et al.*, [*Introduction to Representation Theory*](http://math.mit.edu/~etingof/replect.pdf).--&gt;

&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;There is a right adjoint to the forgetful functor &lt;a href=&quot;https://math.stackexchange.com/questions/1922107/the-right-adjoint-of-forgetful-functor&quot;&gt;from the category of sets with &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;-actions &lt;strong&gt;Set(G)&lt;/strong&gt; to &lt;strong&gt;Set&lt;/strong&gt;&lt;/a&gt;.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>ขั้นคิดคำนวณแบบควอนตัม</title>
   <link href="/quantum-algorithms.html"/>
   <updated>2017-08-01T00:00:00+00:00</updated>
   <id>h/quantum-algorithms</id>
   <content type="html">&lt;p&gt;เมื่อหนึ่งปีเต็มที่แล้วถูกชักชวนจากจิรวัฒน์ ตั้งปณิธานนท์ (Center for Quantum Technologies, สิงคโปร์) ให้ไปช่วยเขียนหนังสือให้ความรู้เกี่ยวกับคอมพิวเตอร์เชิงควอนตัม ด้วยความช่วยเหลือตรวจแก้จากบรรณาธิการและผู้ร่วมชะตากรรมเขียนคนอื่นๆทำให้สำเร็จออกมาเป็นหนังสือ(ฟรี) &lt;a href=&quot;http://www.ebooks.in.th/ebook/45594/&quot;&gt;&lt;em&gt;รูป รส กลิ่น เสียง สัมผัส ไอทีควอนตัม (๓): “คอมพิวเตอร์เชิงควอนตัม”&lt;/em&gt;&lt;/a&gt; จนได้ แต่ส่วนที่มีคณิตศาสตร์ที่เกินกว่าการนับเลขถูกตัดออกหมดก็เลยอยากจะลงต้นฉบับที่มีคณิตศาสตร์ไว้ ณ ที่นี้เพื่อความเข้าใจคอมพิวเตอร์เชิงควอนตัมที่แม่นยำและลึกซึ้งขึ้นครับ (ขอขอบคุณปัณฑิตา ผลิตผลการพิมพ์ ที่อ่านและวิจารณ์ดราฟท์แรกอย่างละเอียดจนกลายมาเป็นต้นฉบับนี้ได้ แต่ข้อผิดพลาดใดๆหรือภาษาที่ไม่สละสลวยเป็นความรับผิดชอบของผมเอง)&lt;/p&gt;
&lt;hr /&gt;
&lt;h1 id=&quot;อลกอรธมนนสำคญไฉน&quot;&gt;อัลกอริธึมนั้นสำคัญไฉน&lt;/h1&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/08-2017/koenigsberg-merian-erben_1652.jpg&quot; style=&quot;width: 628px;&quot;/&gt;
&lt;/center&gt;

&lt;p&gt;นี่คือหน้าตาของเมืองเคอนิกสแบร์ก (Königsberg) ในศตวรรษที่ 18 ที่แม่น้ำ Pregel ไหลผ่านตัดแยกตัวเมืองเป็นสี่ผืนดินที่เชื่อมกันด้วยสะพานเจ็ดสะพาน (ก่อนจะเหลือแค่ห้าจากการทิ้งระเบิดสมัยสงครามโลกครั้งที่สอง) ชาวเมืองเคอนิกสแบร์กมักจะใช้เวลาบ่ายวันอาทิตย์เดินชมเมืองอันสวยงามของพวกเขา จนมีคนนึกสนุกตั้งปัญหาขึ้นมาว่าเป็นไปได้ไหมที่จะเดินข้ามสะพานครบทั้งเจ็ดสะพานโดยไม่ข้ามสะพานใดสะพานหนึ่งมากกว่าหนึ่งครั้ง?&lt;/p&gt;
&lt;p&gt;อีกปัญหาที่มีความคล้ายกันมากมาจากเกมที่วิลเลียม โรวัน แฮมิลตัน (William Rowan Hamilton) ชาวไอริชคิดขึ้นในปี 1857 ชื่อว่าเกมไอโคเซียน (Icosian) เป้าหมายของเกมคือการหาเส้นทางเดินบนขอบ (ที่เป็นเส้นหนึ่งมิติ ไม่ใช่หน้า) ของรูปเหลี่ยม 12 หน้า (dodecahedron) ที่ผ่านทุกมุมแต่ไม่ผ่านมุมใดมุมหนึ่งมากกว่าหนึ่งครั้ง&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/08-2017/dodecahedron.png&quot; style=&quot;width: 300px;&quot;/&gt;
&lt;/center&gt;

&lt;p&gt;ในทางคณิตศาสตร์แล้ว ทั้งสองปัญหาคือปัญหาเกี่ยวกับการเดินบนเน็ตเวิร์คซึ่งเป็นโครงสร้างที่ประกอบด้วยเส้นเชื่อม (edge) และโหนด (หรือจุดยอด vertex) เกมไอโคเซียนถามหาเส้นทางเดินบนเน็ตเวิร์คที่ผ่านทุกๆโหนดแต่ไม่ผ่านโหนดใดโหนดหนึ่งมากกว่าหนึ่งครั้ง ในขณะที่ปัญหาสะพานทั้งเจ็ดของเคอนิกสแบร์กถามหาเส้นทางเดินบนเน็ตเวิร์คที่ผ่านทุกๆเส้นเชื่อมแต่ไม่ผ่านเส้นเชื่อมใดเส้นเชื่อมหนึ่งมากกว่าหนึ่งครั้ง&lt;/p&gt;
&lt;p&gt;เลออนฮาร์ด ออยเลอร์ (Leonhard Euler) ชาวสวิตเซอร์แลนด์ที่ช่วงนั้นทำงานอยู่ที่เซนต์ ปีเตอร์สเบอร์ก สังเกตว่าปัญหาสะพานทั้งเจ็ดของเคอนิกสแบร์กจะมีคำตอบก็ต่อเมื่อไม่มีโหนดที่มีเส้นออกจากโหนดเป็นจำนวนคี่ หรือถ้ามีก็มีแค่สองโหนด เพราะการผ่านโหนดใดโหนดหนึ่งโดยไม่เดินซ้ำเส้นทางเดิมจะต้องมีทางเข้าทางหนึ่งกับทางออกทางหนึ่ง แต่โหนดเริ่มต้นไม่ต้องมีทางเข้าและโหนดสุดท้ายไม่ต้องมีทางออก คำตอบของออยเลอร์ลึกซึ้งที่ว่ามันไม่ใช่คำตอบของปัญหาสะพานทั้งเจ็ดของเคอนิกสแบร์กปัญหาเดียวแต่เป็นคำตอบของการเดินโดยไม่ซ้ำเส้นทางเดิมบนทุกๆเน็ตเวิร์ค และมันยังบอกขั้นตอนการหาคำตอบหรือ&lt;strong&gt;อัลกอริธึม&lt;/strong&gt; (algorithm) ที่มีประสิทธิภาพสำหรับทุกๆเน็ตเวิร์คโดยการนับจำนวนเส้นเชื่อมที่ออกจากโหนดแต่ละโหนดเท่านั้น&lt;/p&gt;
&lt;p&gt;ทว่าจนถึงทุกวันนี้ยังไม่มีใครรู้อัลกอริธึมเร็วๆสำหรับเกมไอโคเซียนที่ใช้ได้กับทุกๆเน็ตเวิร์ค ซึ่งน่าคิดเพราะเกมไอโคเซียนต่างกับปัญหาสะพานทั้งเจ็ดของเคอนิกสแบร์กเพียงแค่เปลี่ยนเส้นเชื่อมเป็นโหนดเท่านั้นเอง อัลกอริธึมที่ใช้ได้กับทั้งสองปัญหาก็คือลองเดินมันโง่ๆทุกเส้นทางบนเน็ตเวิร์คแล้วดูว่ามีเส้นทางที่เป็นคำตอบไหม แต่วิธีนี้อาจจะต้องใช้เวลาเป็นทวีคูณ (exponential) ของขนาดของเน็ตเวิร์ค จำนวนที่เป็นทวีคูณนี่ใหญ่ขนาดกันนะ?&lt;/p&gt;
&lt;p&gt;ในนิทานเรื่องหนึ่ง พระราชาเรียกผู้ที่คิดเกมหมากรุกได้เป็นคนแรกมาเข้าเฝ้าหวังจะให้รางวัลตอบแทนอย่างยิ่งใหญ่สมกับผลงานของเขา คนผู้นั้นก็ขอรางวัลเป็นข้าวสารหนึ่งเม็ดในช่องแรกของกระดานหมากรุก สองเม็ดในช่องที่สอง สี่เม็ดในช่องที่สาม… เพิ่มขึ้นที่ละสองเท่าตัวๆจนเต็ม 64 ช่องของกระดานหมากรุก พระราชาก็รับปากถึงแม้ในใจจะคิดว่าข้าวสารแค่นี้จะมีค่าสักเท่าไรเชียว จนกระทั่งคนรับใช้กะปริมาณข้าวสารที่ต้องให้&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1,000,000 เม็ดในช่องที่ 20&lt;/li&gt;
&lt;li&gt;1,000,000,000,000 เม็ดในช่องที่ 40&lt;/li&gt;
&lt;li&gt;18,000,000,000,000,000,000 เม็ดในช่องสุดท้ายซึ่งถ้าตีเป็นน้ำหนักก็จะได้ประมาณ 460,000,000 ตัน&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/08-2017/rice-on-chessboard.jpeg&quot; style=&quot;width: 750px;&quot;/&gt;
&lt;/center&gt;

&lt;p&gt;บางเวอร์ชันของเรื่องเล่านี้จบลงที่พระราชาสั่งประหารคนผู้นั้นเมื่อรู้ตัวว่าโดนหลอกเข้าให้แล้ว บทเรียนหนึ่งของเรื่องนี้ก็คืออย่าไปกวนตีนคนที่มีอำนาจมากนัก แต่อีกบทเรียนที่สำคัญกว่าก็คือจำนวนที่โตแบบทวีคูณนั้นอาจจะโตเกินจินตนาการของเราได้ ถึงปัญหาจะไม่ใหญ่มาก แต่ถ้ามีแต่อัลกิริธึมที่ต้องใช้เวลาเป็นทวีคูณ ถึงจะใช้ซูเปอร์คอมพิวเตอร์ที่ทำการคำนวณได้กว่า 10 ยกกำลัง 15 ขึ้นตอนในหนึ่งวินาทีก็ยังอาจต้องใช้เวลาเกินอายุปัจจุบันของเอกภพ (13.7 พันล้านปี) ในขณะที่ดวงอาทิตย์อยู่ได้อีกแค่ประมาณห้าพันล้านปี อัลกอริธึมที่ช้าจึงไม่ใช่แค่ไม่ทันใจ แต่อาจจะไม่ทันโลกแตกด้วยซ้ำ! ปัญหาที่ต้องใช้เวลาเป็นทวีคูณในการแก้ถือเป็นปัญหาที่&lt;strong&gt;ยาก&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;บตรเครดต-เสยงดนตร-และคอมพวเตอรควอนตม&quot;&gt;บัตรเครดิต, เสียงดนตรี, และคอมพิวเตอร์ควอนตัม&lt;/h1&gt;
&lt;p&gt;ไอเดียของคอมพิวเตอร์ที่อาศัยพฤติกรรมเชิงควอนตัมของสสารในการคำนวณมีมาตั้งแต่ปี 1980 แล้วแต่ในตอนนั้นยังไม่ชัดเจนว่าคอมพิวเตอร์ควอนตัมจะแก้ปัญหายากๆได้เร็วกว่าคอมพิวเตอร์ธรรมดาขนาดไหน จุดเปลี่ยนที่ทำให้คนหันมาสนใจคอมพิวเตอร์ควอนตัมในวงกว้างมาจากวงการที่แทบจะไม่เกี่ยวข้องกับฟิสิกส์เลย: วงการรหัสลับ&lt;/p&gt;
&lt;p&gt;การส่งข้อความลับจะต้องมีกุญแจเข้ารหัส (encrypt) และกุญแจถอดรหัส (decrypt) รหัสลับก่อนสงครามโลกครั้งที่สองมักใช้กุญแจเดียวกันทั้งในการเข้าและถอดรหัส จึงถูกเรียกว่ากุญแจแบบสมมาตร (symmetric key) รหัสแบบนี้สามารถให้ความปลอดภัยอย่างสมบูรณ์แบบได้ในทางทฤษฎีเช่น one-time pad ที่มีกุญแจเป็นข้อความสุ่มมั่วๆเอามาใช้แปลงข้อความจริง ถ้ารู้ข้อความสุ่มนั้นก็จะกู้ข้อความจริงกลับมาได้ แต่กุญแจต้องใช้แล้วทิ้ง ห้ามใช้ซ้ำกัน ตามชื่อว่า one-time (การที่โปรเจ็กต์ VENONA ของ NSA สหรัฐอเมริกาจับตัวสายลับโซเวียตในช่วงสงครามโลกครั้งที่สองได้ก็เชื่อกันว่ามาจากการใช้กุญแจซ้ำของโซเวียตที่มีเหตุจากการเร่งการผลิตกุญแจลับเพราะการบุกของเยอรมัน) ยิ่งข้อความลับยาวกุญแจก็ยิ่งต้องใหญ่ นอกจากนี้การที่ทั้งผู้ส่งและผู้รับจะต้องมีกุญแจเดียวกันก็แปลว่าจะต้องมีการส่งกุญแจกันไปมา ถ้าถูกดักตีหัวขโมยกุญแจก็เสร็จ&lt;/p&gt;
&lt;p&gt;ในปัจจุบันรหัสลับส่วนใหญ่ใช้กุญแจคนละดอกในการเข้าและถอดรหัส โดยกุญแจเข้ารหัสเป็นกุญแจสาธารณะ (public key) ที่ใครๆก็รู้ได้ ระบบแบบนี้ไม่มีทางปลอดภัยอย่างสมบูรณ์แบบเพราะข้อมูลของกุญแจถอดรหัสก็อยู่ในกุญแจเข้ารหัส (ทั้งสองกุญแจมีความสัมพันธ์กันเพราะกุญแจถอดรหัสต้องแก้สิ่งที่กุญแจเข้ารหัสทำ) การค้นพบครั้งสำคัญในวงการรหัสลับคือการใช้ปัญหาการแยกตัวประกอบที่เชื่อว่าไม่มีอัลกอริธึมใดๆในปัจจุบันแก้ได้เร็วพอมาป้องกันการกู้กุญแจถอดรหัสจากกุญแจเข้ารหัส การเข้ารหัสนี้เรียกว่าการเข้ารหัสแบบ RSA &lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; และเป็นระบบการเข้ารหัสที่ใช้กันแพร่หลายในการเข้าเวบอย่างปลอดภัย (https), การป้องกันพาสเวิร์ด, หรือบัตรเครดิต ทุกครั้งที่เราซื้อของออนไลน์ ความปลอดภัยของเราขึ้นอยู่กับ RSA&lt;/p&gt;
&lt;p&gt;ถ้าดูนาฬิกาเป็นก็จะเข้าใจไอเดียของ RSA ได้ สังเกตว่าในการบวก-ลบเวลา เราจะไม่พูดว่า “10 ชั่วโมงหลัง 20 นาฬิกาคือ 30 นาฬิกา” แต่เราจะเริ่มนับส่วนที่เกิน 24 ใหม่ นอกจากบวก-ลบแล้วการคูณหรือการยกกำลังในระบบเลขคณิตแบบนี้ก็เป็นสิ่งที่ทำได้เพราะการคูณคือการบวกซ้ำๆกันและการยกกำลังคือการคูณซ้ำๆกัน ซึ่งคนส่วนใหญ่คงจะไม่เคยทำ แต่ถ้าลองทำดูจะพบสิ่งหนึ่งที่น่าสนใจคือการคูณเลขด้วยตัวมันเองซ้ำๆจะทำให้ย้อนกลับมายังเลขตั้งต้นได้ ตารางด้านล่างเป็นผลคูณ 2 ด้วยตัวมันเองถ้ามี 15 ชั่วโมงในหนึ่งวัน&lt;/p&gt;
&lt;!-- https://stackoverflow.com/questions/24127507/is-it-possible-to-center-tables-in-a-markdown-file --&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;กำลัง&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;1&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;2&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;3&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;4&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;5&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;6&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;7&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;ค่าของ 2 ยกกำลัง&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;2&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;4&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;8&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;2&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;4&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;

&lt;p&gt;การเข้ารหัสแบบ RSA แปลงข้อความให้เป็นจำนวนเต็มก่อน เรียกจำนวนนี้ว่า m (message) กุญแจสาธารณะคือจำนวนของ“ชั่วโมง” N และตัวเลข x ที่ทำให้ผู้เข้ารหัสสามารถคำนวณ m ยกกำลัง x ในเลขคณิตแบบนาฬิกาได้ เมื่อถึงมือผู้รับรหัส มีกุญแจลับ y ที่บอกว่าจะต้องยกกำลังต่ออีกเท่าไรจึงจะได้ข้อความ m กลับมา การจะรู้ y ได้จะต้องแยกตัวประกอบของ N ซึ่งเป็นส่วนหนึ่งของกุญแจสาธารณะที่ใครๆก็มี แต่ปัญหาก็คือทุกๆอัลกอริธึมการแยกตัวประกอบที่มีในปัจจุบันต้องใช้เวลาเป็นทวีคูณ การจะถอดรหัส RSA ที่ N เป็นเลขหลายร้อยหลักอาจจะต้องใช้เวลาเป็นล้านปี&lt;/p&gt;
&lt;p&gt;แต่ถ้ามีคอมพิวเตอร์ควอนตัม การแยกตัวประกอบเลขหลายร้อยหลักจะใช้เวลาเพียงไม่กี่วินาที! &lt;a href=&quot;#fn2&quot; class=&quot;footnoteRef&quot; id=&quot;fnref2&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; สิ่งที่ต่างก็คือคอมพิวเตอร์ควอนตัมมีอัลกอริธึมควอนตัมที่สามารถหาทางลัดในการแก้บางปัญหาได้ การทำงานของอัลกอริธึมควอนตัมแยกตัวประกอบค่อนข้างซับซ้อนแต่หัวใจของมันมาจากการทำงานร่วมกันของการยกกำลังในเลขคณิตนาฬิกากับการแปลงฟูเรียร์ (Fourier transform) การแปลงฟูเรียร์เป็นการแตกคลื่นเป็นผลรวมของหลายๆคลื่นที่มีความถี่เฉพาะตัว ไม่ต่างกับการแยกเสียงดนตรีเป็นโน๊ตความถี่ต่างๆ ทำให้สามารถขับหรือลดเสียงของเครื่องดนตรีแต่ละชนิดแยกกันได้ หน้าที่ของการแปลงฟูเรียร์ในอัลกอริธึมควอนตัมคือการหาคาบ (ส่วนกลับของความถี่) ของการยกกำลังในเลขคณิตนาฬิกา เมื่อรู้คาบ — จำนวนครั้งที่ต้องคูณเพื่อให้ได้ค่าเดิมกลับมา — ก็จะทำให้แยกตัวประกอบและรู้ y ได้ จึงทำลายรหัสลับ RSA ได้&lt;/p&gt;
&lt;p&gt;บางปัญหาที่ยากสำหรับคอมพิวเตอร์ธรรมดาเป็นปัญหาที่ง่ายสำหรับคอมพิวเตอร์ควอนตัม นี่เป็นการค้นพบของ ปีเตอร์ ชอร์ (Peter Shor) ชาวอเมริกันในปี 1994 ที่สั่นสะเทือนวงการการถอดรหัสลับและฟิสิกส์ ปัจจุบันยังไม่มีคอมพิวเตอร์ควอนตัมขนาดใหญ่พอที่จะทำแบบนี้ได้ อินส์บรุค (Innsbruck) จับมือกับ MIT เพิ่งจะตีพิมพ์การแยกตัวประกอบ 15 ออกเป็น 3x5 ได้สำเร็จด้วยคอมพิวเตอร์ควอนตัมจิ๋ว 5 อะตอมเมื่อปีที่แล้ว &lt;a href=&quot;#fn3&quot; class=&quot;footnoteRef&quot; id=&quot;fnref3&quot;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; แต่ก็ไม่ต้องห่วงว่าถ้าทำสำเร็จโลกนี้จะไม่มีความลับอีกต่อไปเพราะนักวิทยาศาสตร์ได้เตรียมรหัสลับต้านทานอัลกอริธึมควอนตัมไว้เรียบร้อยแล้ว (&lt;a href=&quot;https://en.wikipedia.org/wiki/Post-quantum_cryptography&quot;&gt;post-quantum cryptography&lt;/a&gt;)&lt;/p&gt;
&lt;h1 id=&quot;เรขาคณตของอลกอรธมควอนตม&quot;&gt;เรขาคณิตของอัลกอริธึมควอนตัม&lt;/h1&gt;
&lt;p&gt;ความเข้าใจผิดที่ได้ยินกันแพร่หลายมากที่สุดเกี่ยวกับคอมพิวเตอร์ควอนตัมคือคอมพิวเตอร์ควอนตัมเหมือนกับคอมพิวเตอร์ธรรมดาที่ประมวลผลแบบคู่ขนาน แก้ปัญหาโดยการเช็คคำตอบทุกคำตอบที่เป็นไปได้พร้อมๆกัน ซึ่งถ้าทำได้จริงก็จะมหัศจรรย์มาก ไม่ว่าปัญหาใดๆ อัลกอริธึมควอนตัมที่ลองทุกคำตอบก็จะแก้ได้ในหนึ่งขั้นตอนเท่านั้น แต่ความจริงไม่ง่ายแบบนั้น ซึ่งก็อาจจะเป็นเรื่องดีเพราะการเข้ารหัสลับที่ต้านทานอัลกอริธึมควอนตัมก็ต้องอาศัยปัญหาที่ยากสำหรับทั้งอัลกอริธึมธรรมดาและอัลกอริธึมควอนตัม ตัวอย่างที่ดีเยี่ยมในการแสดงให้เห็นการความแตกต่างของการทำงานของอัลกอริธึมธรรมดากับอัลกอริธึมควอนตัมจึงเป็นอัลกอริธึมควอนตัมในการเช็คคำตอบที่ลอฟ โกรเวอร์ (Lov Grover) ชาวอเมริกัน-อินเดีย คิดขึ้นมาในปี 1996 หลังจากชอร์ 2 ปี&lt;/p&gt;
&lt;p&gt;การจะเข้าใจการทำงานของอัลกอริธึมนี้จะต้องรู้พื้นฐานของทฤษฎีควอนตัมเสียก่อนทฤษฎีควอนตัมรวมคณิตศาสตร์ของความน่าจะเป็นกับเรขาคณิต แต่เป็นเรขาคณิตที่มีแต่ทิศทาง ไม่มีระยะทาง (สำหรับคนที่รู้จักเวกเตอร์ จึงไม่ใช่เรขาคณิตของเวกเตอร์เสียทีเดียวเพราะเวกเตอร์มีทั้งขนาดและทิศทาง) ในเรขาคณิตแบบนี้ เหนือกับใต้ถือว่าเป็นทิศเดียวกันเพราะการเดินไปทางเหนือก็คือการเดินไปทางใต้ด้วยระยะทางติดลบ พูดอีกอย่างก็คือมุม 180 องศากลายเป็น 0 องศา (แทนที่ 360 องศาจะเป็น 0 องศา) แต่ความใกล้กันของสองทิศทางก็ยังวัดได้ด้วยมุมที่ไม่เกิน 90 องศา สิ่งที่สำคัญคือยังมีทิศทางที่ตั้งฉากกัน (ทำมุม 90 องศา) นิยามของมิติจึงเหมือนกับในเรขาคณิตปกติ คือจำนวนที่มากที่สุดของทิศทางที่ตั้งฉากกัน เหมือนที่ 3 มิติมีความกว้าง ความยาว และความสูง &lt;a href=&quot;#fn4&quot; class=&quot;footnoteRef&quot; id=&quot;fnref4&quot;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ระบบฟิสิกส์ไม่ว่าจะเป็นอะตอม ไอออน ช่องว่างในเพชร หรือวงจรไฟฟ้ายิ่งยวด ที่จะได้เจอในบทถัดๆไปของหนังสือเล่มนี้จะมีสถานะควอนตัม (quantum state) ของมันเองถ้าได้รับการป้องกันอย่างดีพอจากสิ่งรบกวนภายนอกไม่ว่าจะเป็นสนามแม่เหล็กไฟฟ้าหรือความร้อน ซึ่งตามทฤษฎีควอนตัมแล้ว ทิศทางเป็นตัวแทนเชิงคณิตศาสตร์ของสถานะควอนตัม ทิศทางนี้ไม่ใช่ทิศทางจริงๆในทางภูมิศาสตร์ แต่เป็นทิศทางในจำนวนมิติที่ถูกกำหนดโดยฟิสิกส์ของระบบนั้นๆ เช่นสถานะควอนตัมของสปินของอิเล็กตรอนถูกแทนด้วยทิศทางในสองมิติ&lt;/p&gt;
&lt;p&gt;การวัดในทฤษฎีควอนตัมคือการถามระบบฟิสิกส์ว่าสถานะควอนตัมของเธอชี้ไปทางนี้หรือเปล่า? ถ้าทิศที่ถามขนานกับทิศที่มันชี้พอดีก็จะได้คำตอบว่า “ใช่” เสมอ ถ้าทิศที่ถามตั้งฉากกับทิศที่ชี้ก็จะได้คำตอบว่า “ใม่” เสมอ แต่จะเกิดอะไรขึ้นถ้าทิศที่ถามไม่ขนานหรือตั้งฉากเสียทีเดียวล่ะ? ทฤษฎีควอนตัมกำหนดว่าความน่าจะเป็นที่จะได้คำตอบ “ใช่” มีค่าเป็นกำลังสองของโคไซน์ของมุมระหว่างสองทิศนั้น&lt;/p&gt;
&lt;!-- https://stackoverflow.com/questions/24127507/is-it-possible-to-center-tables-in-a-markdown-file --&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;องศา&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;0&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;30&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;45&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;60&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;90&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;120&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;135&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;150&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;180&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;โคไซน์กำลังสอง&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;3/4&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1/2&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1/4&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;0&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1/4&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1/2&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;3/4&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;

&lt;p&gt;สมมติว่าปัญหาหนึ่งมีคำตอบที่เป็นไปได้ 4 คำตอบ ปกติแล้วจะต้องเช็คคำตอบทีละคำตอบ จึงเป็นไปได้ว่าจะต้องเช็คถึง 4 ครั้งกว่าจะได้คำตอบที่ถูกต้อง สำหรับคอมพิวเตอร์ควอนตัม 4 คำตอบนี้แทนด้วย 4 ทิศทางที่ตั้งฉากกัน (จึงมี 4 มิติ) การเช็คคำตอบด้วยการวัดก็ไม่ช่วยอะไรเช่นกัน แต่คอมพิวเตอร์ควอนตัมสามารถเช็คคำตอบโดยปราศจากการวัดได้โดยการเก็บคำตอบ “ใช่” หรือ “ไม่ใช่” ไว้กับตัวมันเอง ซึ่งถ้าเราไม่ไปวัดก็จะไม่รู้ ดูเป็นความสามารถที่ไร้ประโยชน์สิ้นดี แต่ทริคของอัลกอริธึมควอนตัมคือการแปลงการเช็คคำตอบแบบหลังไปเป็นการพลิกสถานะควอนตัมที่ขนานกับทิศของคำตอบ ถ้าคำตอบอยู่ในทิศเหนือ-ใต้ (อย่าลืมว่าเป็นทิศเดียวกันในเรขาคณิตแบบควอนตัม) แล้วสถานะควอนตัมชี้ไปทางเหนือ การเช็คคำตอบก็จะพลิกมันมาทางทิศใต้ สถานะควอนตัมที่ชี้ไปทางใต้ก็จะถูกพลิกไปยังทิศเหนือ และปล่อยทิศทางที่ตั้งฉากกับคำตอบไว้คงเดิม ทริคนี้จึงไม่มีผลต่อความน่าจะเป็นของผลการวัดแต่อย่างใด แต่มันทำให้อัลกอริธึมควอนตัมหาหนึ่งในสี่คำตอบที่ถูกต้องเจอจากการเช็ค (พลิก) เพียงหนึ่งครั้งเท่านั้น! เริ่มต้นด้วยทิศที่มีโอกาสได้คำตอบทุกคำตอบเท่าๆกันหมดคือ 1/4 ทิศนี้ทำมุม 60 องศากับคำตอบ s (solution) เพราะว่าโคไซน์กำลังสองของ 60 องศาเท่ากับ 1/4&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/08-2017/grover2a.png&quot; style=&quot;width: 300px;&quot;/&gt;
&lt;/center&gt;

&lt;p&gt;จากนั้นก็เช็คคำตอบเพื่อพลิกมัน&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/08-2017/grover2b.png&quot; style=&quot;width: 650px;&quot;/&gt;
&lt;/center&gt;

&lt;p&gt;แล้วก็พลิกอีกครั้งผ่านทิศตั้งต้นก็จะได้คำตอบที่ถูกต้องด้วยความน่าจะเป็น 100%&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/08-2017/grover2c.png&quot; style=&quot;width: 650px;&quot;/&gt;
&lt;/center&gt;

&lt;p&gt;เมื่อคำตอบที่เป็นไปได้มีจำนวนเยอะขึ้น ทิศทางตั้งต้นก็จะอยู่ห่างจากทิศของคำตอบมากขึ้น การพลิกสองสเต็ป (จากการเช็คคำตอบ ตามด้วยการพลิกผ่านทิศตั้งต้น) แต่ละครั้งจะทำให้ขยับเข้าใกล้คำตอบมากขึ้นเรื่อยๆ หากทำการคำนวณก็จะประมาณได้ว่าจำนวนครั้งที่อัลกอริธึมนี้ต้องเช็คคำตอบคือรากที่สองของจำนวนคำตอบที่เป็นไปได้ &lt;a href=&quot;#fn5&quot; class=&quot;footnoteRef&quot; id=&quot;fnref5&quot;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; ถ้าคอมพิวเตอร์ธรรมดาต้องเช็คคำตอบหนึ่งล้านครั้ง คอมพิวเตอร์ควอนตัมก็จำเป็นต้องเช็คเพียงแค่หนึ่งพันครั้ง ไม่ได้เร็วขึ้นแบบทวีคูณเหมือนอัลกอริธึมแยกตัวประกอบของชอร์แต่ก็ช่วยได้เยอะ&lt;/p&gt;
&lt;p&gt;ในมุมมองหนึ่ง สิ่งที่อัลกอริธึมควอนตัมทำจึงเป็นเพียงการขยับลูกศรไปมา ซึ่งพูดเหมือนง่ายแต่เป็นความท้าทายมาก ถ้าอยากรู้ว่าการควบคุมสถานะควอนตัมนั้นทำกันในแลบได้อย่างไรก็สามารถอ่านบทความที่เขียนและเรียบเรียงโดยนักศึกษาและนักวิทยาศาสตร์ไทยท่านอื่นๆ ได้ใน &lt;a href=&quot;http://www.ebooks.in.th/ebook/45594/&quot;&gt;&lt;em&gt;รูป รส กลิ่น เสียง สัมผัส ไอทีควอนตัม (๓): “คอมพิวเตอร์เชิงควอนตัม”&lt;/em&gt;&lt;/a&gt; ครับ&lt;/p&gt;
&lt;h1 id=&quot;อางอง&quot;&gt;อ้างอิง&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cristopher Moore และ Stephen Mertens, “Quantum Computation” ใน &lt;em&gt;The Nature of Computation&lt;/em&gt;, Cambridge University Press (2011).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Scott Aaronson, “Crypto” ใน &lt;em&gt;Quantum Computing Since Democritus&lt;/em&gt;, Cambridge University Press (2013).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;มาจากตัวอักษรแรกของชื่อผู้ค้นพบ Ron Rivest, Adi Shamir, และ Leonard Adleman&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn2&quot;&gt;&lt;p&gt;ถ้าสมมติว่าคอมพิวเตอร์ควอนตัมมีความเร็ว CPU พอๆกับของคอมพิวเตอร์ปัจจุบัน&lt;a href=&quot;#fnref2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn3&quot;&gt;&lt;p&gt;Thomas Monz et al., “&lt;a href=&quot;http://science.sciencemag.org/content/351/6277/1068&quot;&gt;Realization of a scalable Shor algorithm&lt;/a&gt;” &lt;em&gt;Science&lt;/em&gt; 351 1068 (2016).&lt;a href=&quot;#fnref3&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn4&quot;&gt;&lt;p&gt;สำหรับผู้รู้ทฤษฎีควอนตัม ที่พูดไปไม่ใช่ความจริงทั้งหมดเพราะมุมนี้สามารถเป็นจำนวนเชิงซ้อนได้! แต่ทุกมุมในบทความนี้เป็นจำนวนจริง&lt;a href=&quot;#fnref4&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn5&quot;&gt;&lt;p&gt;จริงๆคือ &lt;span class=&quot;math&quot;&gt;\(\pi/4\)&lt;/span&gt; คูณรากที่สองของจำนวนคำตอบที่เป็นไปได้&lt;a href=&quot;#fnref5&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>First Post</title>
   <link href="/first-post.html"/>
   <updated>2017-01-03T00:00:00+00:00</updated>
   <id>h/first-post</id>
   <content type="html">&lt;p&gt;First published: &lt;em&gt;20 Jul 2016&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;First post on my Jekyll-powered blog!&lt;/p&gt;
&lt;p&gt;I’ve been blogging on &lt;a href=&quot;https://ninnatdangniam.wordpress.com/&quot;&gt;Wordpress&lt;/a&gt; for a long time (in Thai) but despite how easy it is to setup the blog, there isn’t much I can do without paying. Now you can follow &lt;a href=&quot;https://ninnat.github.io/README.html&quot;&gt;what I did&lt;/a&gt; and get your own blog hosted on a free (public) Git repository.&lt;/p&gt;
&lt;p&gt;Finding a blog that functions without a hassle is even harder if you are a math blogger, but that is not a problem here. Equations are written in &lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot;&gt;Markdown&lt;/a&gt; and displayed using &lt;a href=&quot;https://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt;. Math in a paragraph (in-line math) is delimited by &lt;code&gt;$...$&lt;/code&gt;, while displaying math in its own paragraph uses &lt;code&gt;$$...$$&lt;/code&gt;. Use &lt;code&gt;\begin{aligned}...\end{aligned}&lt;/code&gt; for aligned equations and &lt;code&gt;\begin{aligned}...\end{aligned}&lt;/code&gt; for numbered aligned equations. (Both delimiters have to be placed inside &lt;code&gt;$$...$$&lt;/code&gt;.) A quick guide on MathJax syntax can be found &lt;a href=&quot;http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s test this by writing the Maxwell’s equations in cgs units:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[
\begin{align}
\nabla \cdot \mathbf{E} &amp;amp;= 4\pi \rho , \\
\nabla \times \mathbf{E} &amp;amp;= -\frac{1}{c} \frac{\partial \mathbf{B}}{\partial t} , \\
\nabla \cdot \mathbf{B} &amp;amp;= 0, \\
\nabla \times \mathbf{B} &amp;amp;= \frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}.
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Another indispensable feature that I’ve always longed for is the popup footnote. Digital footnotes today are often still implemented as if they are in print media. You follow the link to the bottom of the post and then have to find a way back to where you were in the main text, thus breaking the flow of reading. (And maybe it’s just me but it’s tempting to take a peek at footnotes even when I know they aren’t necessary to the main text.) A much better way to implement a digital footnote is using, for example, &lt;a href=&quot;http://www.bigfootjs.com/&quot;&gt;Bigfoot&lt;/a&gt; like this. &lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; All you have to do is pasting the css into &lt;code&gt;/assets/css/style.css&lt;/code&gt;, putting the javascript file to, say, &lt;code&gt;/assets/js&lt;/code&gt; and calling it with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot; src=&amp;quot;/assets/js/bigfoot.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
    $.bigfoot({
        activateCallback: function($popover, $button) {
                if (MathJax &amp;amp;&amp;amp; !$button.data(&amp;#39;mathjax-processed&amp;#39;)) {
                        var content_wrapper = $popover.find(&amp;#39;.bigfoot-footnote__content&amp;#39;)[0];
                        MathJax.Hub.Queue([&amp;#39;Typeset&amp;#39;, MathJax.Hub, content_wrapper]);
                        MathJax.Hub.Queue(function () {
                                $button.attr(&amp;#39;data-bigfoot-footnote&amp;#39;, content_wrapper.innerHTML);
                                $button.data(&amp;#39;mathjax-processed&amp;#39;, true);
                        });
                }
        }
    });
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;within &lt;code&gt;/_includes/javascript.html&lt;/code&gt;. This code, created by &lt;a href=&quot;https://esham.io/2014/07/mathjax-and-bigfoot&quot;&gt;Benjamin Esham&lt;/a&gt;, enables MathJax in the footnote. You also have the option to show or hide footnotes in the footer. I decide to show it for searchability.&lt;/p&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;Alan Jacobs, &lt;a href=&quot;http://www.theatlantic.com/technology/archive/2012/03/the-technology-of-a-better-footnote/254403/&quot;&gt;“The Technology of a Better Footnote,”&lt;/a&gt; &lt;em&gt;The Atlantic&lt;/em&gt;, March 2012.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>ควอนตัมฟิสิกส์สำหรับทารก</title>
   <link href="/quantum-for-babies.html"/>
   <updated>2016-12-27T00:00:00+00:00</updated>
   <id>h/quantum-for-babies</id>
   <content type="html">&lt;p&gt;อาจจะเคยเห็นหนังสือ &lt;em&gt;Quantum Physics for Babies&lt;/em&gt; ที่ Mark Zuckerberg อ่านให้ลูกฟัง&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/assets/img/posts/zuckerberg.jpg&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;หรือที่ “Antman” Paul Rudd ใช้เป็นที่พึ่งเพื่อหาวิธีเอาชนะ Stephen Hawking ในเกมหมากรุกควอนตัม&lt;/p&gt;
&lt;center&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Hi0BzqV_b44?t=5m4s&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;

&lt;p&gt;&lt;em&gt;Quantum Physics for Babies&lt;/em&gt; เป็นหนังสือที่ &lt;a href=&quot;https://csferrie.com/&quot;&gt;Chris Ferrie&lt;/a&gt; เขียนขึ้นมาให้ลูกของเขาเองระหว่างที่ทำงานเป็นโพสต์ด็อก(นักวิจัยหลังปริญญาเอก)ที่ University of New Mexico และเรียนรู้วิธี&lt;a href=&quot;https://csferrie.com/2016/11/19/quantum-physics-for-babies/&quot;&gt;ตีพิมพ์ด้วยตนเอง&lt;/a&gt; (เพราะจะได้เล่มตัวอย่างฟรี ถูกกว่าทำเล่มเอง) แล้วดันฮิตติดชาร์ทขึ้นมา คนขอเอาไปแปลเป็นภาษาจีน ภาษาเวียตนาม คราวนี้มีคนไทยคนหนึ่งทำงานร่วมกับเขาที่นิวเม็กซิโก &lt;em&gt;ควอนตัมฟิสิกส์สำหรับทารก&lt;/em&gt;ฉบับภาษาไทยจึงถือกำเนิดขึ้น&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&quot;imgur-embed-pub&quot; lang=&quot;en&quot; data-id=&quot;a/D7MlQ&quot;&gt;
&lt;a href=&quot;//imgur.com/D7MlQ&quot;&gt;Quantum Physics for Babies (THAI)&lt;/a&gt;
&lt;/blockquote&gt;&lt;script async src=&quot;//s.imgur.com/min/embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/center&gt;

&lt;p&gt;คริสมอบสิทธิ์เกี่ยวกับ&lt;em&gt;ควอนตัมฟิสิกส์สำหรับทารก&lt;/em&gt;ฉบับภาษาไทยทั้งหมดให้กับผม (ผู้แปล) จะเอาไปให้สำนักพิมพ์ก็ได้ ถ้าหาสำนักพิมพ์ไม่ได้จะเอาไปแจกฟรีก็ได้ หลังจากรอคำตอบจากคนรู้จักที่ติดต่อให้ช่วยหาสำนักพิมพ์มาพักใหญ่ๆ ผมก็คิดว่าถึงเวลาเอามาแจกฟรีเป็นของขวัญปีใหม่ได้แล้ว สามารถดาวน์โหลดได้เลยที่&lt;a href=&quot;https://github.com/Ninnat/quantum_physics_for_babies_THAI/releases&quot;&gt;ลิงค์นี้&lt;/a&gt; จะเอาไปปรินต์, ดัดแปลง, แชร์ไฟล์นี้หรือไฟล์ที่ได้รับการดัดแปลงให้ลูกเล็กเด็กแดงก็ได้เลยตามสบาย แต่ไม่อนุญาตให้นำไปใช้ทางการค้าและต้องให้เครดิตกับคริสและผม (นินนาท แดงเนียม) เสมอ&lt;/p&gt;
&lt;p&gt;สวัสดีปีใหม่ครับ&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
